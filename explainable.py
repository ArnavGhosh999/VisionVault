#!/usr/bin/env python3
"""
Cell 1: Import Libraries and Setup
Explainable AI for Image Tagging using Kosmos-2
"""

import os
import sys
import json
import re
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
import logging

# Core libraries
import torch
import numpy as np
from PIL import Image, ImageDraw, ImageFont

# Hugging Face Transformers
from transformers import (
    AutoProcessor, 
    AutoModelForVision2Seq,
    Kosmos2ForConditionalGeneration,
    AutoTokenizer
)

# PDF processing
try:
    import fitz  # PyMuPDF
    print("‚úÖ PyMuPDF (fitz) imported successfully")
except ImportError as e:
    print("‚ùå PyMuPDF import failed. Installing...")
    import subprocess
    import sys
    try:
        # Try to install PyMuPDF
        subprocess.check_call([sys.executable, "-m", "pip", "install", "PyMuPDF"])
        import fitz
        print("‚úÖ PyMuPDF installed and imported successfully")
    except Exception as install_error:
        print(f"‚ùå Failed to install PyMuPDF: {install_error}")
        print("üí° Please install manually: pip install PyMuPDF")
        # Use alternative PDF processing
        fitz = None
        print("‚ö†Ô∏è Running without PyMuPDF - PDF processing will be limited")

import sqlite3

# Report generation
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors
import io

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

print("‚úÖ Libraries imported successfully!")
print("üîß Setting up explainable AI system...")

"""
Cell 2: Kosmos-2 Model Loader
Load and initialize the Kosmos-2 model from Hugging Face
"""

class Kosmos2Explainer:
    """Kosmos-2 based explainable AI for image tag generation"""
    
    def __init__(self, model_name: str = "microsoft/kosmos-2-patch14-224"):
        """Initialize Kosmos-2 model"""
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_name = model_name
        
        logger.info(f"üöÄ Loading Kosmos-2 model: {model_name}")
        logger.info(f"üîß Using device: {self.device}")
        
        try:
            # Load processor and model
            self.processor = AutoProcessor.from_pretrained(model_name)
            self.model = Kosmos2ForConditionalGeneration.from_pretrained(
                model_name,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else None
            )
            
            # Move to device if not using device_map
            if not torch.cuda.is_available():
                self.model = self.model.to(self.device)
            
            logger.info("‚úÖ Kosmos-2 model loaded successfully!")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load Kosmos-2 model: {e}")
            raise
    
    def generate_explanation(self, image: Image.Image, existing_tags: List[str]) -> Dict[str, Any]:
        """Generate detailed explanations for image tags"""
        try:
            explanations = {}
            
            # 1. General image understanding - more specific prompt
            general_prompt = "<grounding>List the specific objects, colors, text, shapes, and visual elements you can see in this image."
            inputs = self.processor(text=general_prompt, images=image, return_tensors="pt")
            
            if torch.cuda.is_available():
                inputs = {k: v.to(self.device) if torch.is_tensor(v) else v for k, v in inputs.items()}
            
            with torch.no_grad():
                generated_ids = self.model.generate(
                    pixel_values=inputs["pixel_values"],
                    input_ids=inputs["input_ids"],
                    attention_mask=inputs["attention_mask"],
                    image_embeds=None,
                    image_embeds_position_mask=inputs["image_embeds_position_mask"],
                    use_cache=True,
                    max_new_tokens=100,  # Increased for more detail
                    do_sample=True,      # Enable sampling for variety
                    temperature=0.3,     # Low but not zero
                    top_p=0.8,
                    pad_token_id=self.processor.tokenizer.eos_token_id
                )
            
            generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
            description = self.extract_clean_text(generated_text, general_prompt)
            explanations["general_description"] = description
            
            # 2. Direct visual verification prompts for each tag
            tag_explanations = {}
            
            for tag in existing_tags[:12]:  # Process more tags
                # Use very direct, specific prompts
                verification_prompt = self.create_verification_prompt(tag)
                
                try:
                    inputs = self.processor(text=verification_prompt, images=image, return_tensors="pt")
                    
                    if torch.cuda.is_available():
                        inputs = {k: v.to(self.device) if torch.is_tensor(v) else v for k, v in inputs.items()}
                    
                    with torch.no_grad():
                        generated_ids = self.model.generate(
                            pixel_values=inputs["pixel_values"],
                            input_ids=inputs["input_ids"],
                            attention_mask=inputs["attention_mask"],
                            image_embeds=None,
                            image_embeds_position_mask=inputs["image_embeds_position_mask"],
                            use_cache=True,
                            max_new_tokens=80,   # More tokens for detail
                            do_sample=True,      # Enable sampling
                            temperature=0.4,     # Slightly higher for creativity
                            top_p=0.9,
                            pad_token_id=self.processor.tokenizer.eos_token_id
                        )
                    
                    tag_response = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                    explanation = self.extract_clean_text(tag_response, verification_prompt)
                    
                    # Process the explanation more carefully
                    if explanation and len(explanation) > 15:
                        # Clean and enhance the explanation
                        enhanced = self.process_tag_explanation(explanation, tag)
                        tag_explanations[tag] = enhanced
                    else:
                        # Use image-aware fallback
                        tag_explanations[tag] = self.create_smart_fallback(tag, description)
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed explanation for '{tag}': {e}")
                    tag_explanations[tag] = self.create_smart_fallback(tag, description)
            
            explanations["tag_explanations"] = tag_explanations
            
            # 3. Detailed confidence assessment
            confidence_prompt = "<grounding>Describe the clarity, visibility, and identifiability of the main visual elements in this image."
            
            try:
                inputs = self.processor(text=confidence_prompt, images=image, return_tensors="pt")
                
                if torch.cuda.is_available():
                    inputs = {k: v.to(self.device) if torch.is_tensor(v) else v for k, v in inputs.items()}
                
                with torch.no_grad():
                    generated_ids = self.model.generate(
                        pixel_values=inputs["pixel_values"],
                        input_ids=inputs["input_ids"],
                        attention_mask=inputs["attention_mask"],
                        image_embeds=None,
                        image_embeds_position_mask=inputs["image_embeds_position_mask"],
                        use_cache=True,
                        max_new_tokens=70,
                        do_sample=True,
                        temperature=0.3,
                        pad_token_id=self.processor.tokenizer.eos_token_id
                    )
                
                confidence_response = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                confidence_assessment = self.extract_clean_text(confidence_response, confidence_prompt)
                explanations["confidence_assessment"] = confidence_assessment if confidence_assessment else "Visual elements are clearly distinguishable"
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Confidence assessment failed: {e}")
                explanations["confidence_assessment"] = "Visual elements are clearly distinguishable"
            
            return explanations
            
        except Exception as e:
            logger.error(f"‚ùå Failed to generate explanations: {e}")
            return {
                "general_description": "Unable to analyze visual features",
                "tag_explanations": {},
                "confidence_assessment": "Analysis unavailable"
            }
    
    def create_verification_prompt(self, tag: str) -> str:
        """Create verification prompts that ask for specific visual evidence"""
        tag_lower = tag.lower()
        
        # Very specific prompts that demand visual details
        if tag_lower in ['red', 'blue', 'green', 'yellow', 'orange', 'purple', 'pink', 'brown', 'black', 'white', 'gray', 'grey']:
            return "<grounding>Where exactly do you see " + tag_lower + " color in this image? Describe the specific " + tag_lower + " colored objects, surfaces, or areas."
        
        elif tag_lower in ['stop', 'sign', 'signs']:
            return "<grounding>What specific signs, text, or symbols do you see in this image? Describe their shape, color, and what they say."
        
        elif tag_lower in ['pole', 'post']:
            return "<grounding>Where are the poles or posts in this image? What are they made of and what do they support?"
        
        elif tag_lower in ['tree', 'trees']:
            return "<grounding>Where are the trees in this image? Describe their branches, leaves, and location."
        
        elif tag_lower in ['elephant']:
            return "<grounding>Where do you see elephant-like features in this image? Look for tusks, trunk, ears, or elephant symbols/sculptures."
        
        elif tag_lower in ['lion']:
            return "<grounding>Where do you see lion features in this image? Look for mane, face, body, or lion symbols/sculptures."
        
        elif tag_lower in ['bird']:
            return "<grounding>Where do you see bird features in this image? Look for wings, beak, feathers, or bird symbols."
        
        elif tag_lower in ['flower']:
            return "<grounding>Where are the flowers in this image? Describe their petals, color, and shape."
        
        elif tag_lower in ['gold', 'golden']:
            return "<grounding>Where do you see gold or golden colored elements in this image? Describe the specific golden objects or surfaces."
        
        elif tag_lower in ['street', 'road']:
            return "<grounding>What shows this is a street or road? Look for pavement, road signs, vehicles, or street infrastructure."
        
        elif tag_lower in ['outdoor', 'outside']:
            return "<grounding>What visual evidence shows this is outdoors? Look for sky, natural lighting, or outdoor structures."
        
        elif tag_lower in ['flag']:
            return "<grounding>Where is the flag in this image? Describe its colors, symbols, and design."
        
        else:
            return "<grounding>Where exactly do you see " + tag + " in this image? Describe its appearance, location, and distinctive features."
    
    def process_tag_explanation(self, explanation: str, tag: str) -> str:
        """Process and improve tag explanations"""
        try:
            # Clean the explanation
            cleaned = explanation.strip()
            
            # Remove the prompt echo if present
            if "where exactly do you see" in cleaned.lower():
                parts = cleaned.split("?", 1)
                if len(parts) > 1:
                    cleaned = parts[1].strip()
            
            # Remove generic phrases
            generic_removals = [
                "visual features indicating",
                "detected in the image",
                "can be identified through its distinctive visual characteristics"
            ]
            
            for removal in generic_removals:
                cleaned = cleaned.replace(removal, "").strip()
            
            # If explanation is still too generic or empty, don't use it
            if len(cleaned) < 15 or self.is_still_generic(cleaned):
                return ""
            
            # Ensure proper formatting
            if cleaned and not cleaned[0].isupper():
                cleaned = cleaned.capitalize()
            
            if cleaned and not cleaned.endswith('.'):
                cleaned += "."
            
            # Limit length but preserve content
            if len(cleaned) > 200:
                sentences = re.split(r'[.!?]+', cleaned)
                if sentences and len(sentences[0]) > 20:
                    cleaned = sentences[0].strip() + "."
            
            return cleaned
            
        except Exception as e:
            logger.warning(f"Error processing explanation: {e}")
            return ""
    
    def create_smart_fallback(self, tag: str, general_description: str) -> str:
        """Create smarter fallbacks based on general description"""
        tag_lower = tag.lower()
        desc_lower = general_description.lower() if general_description else ""
        
        # Try to create context-aware fallbacks
        if tag_lower in ['red', 'blue', 'green', 'yellow', 'orange', 'purple', 'pink', 'brown', 'black', 'white', 'gray', 'grey']:
            if "flag" in desc_lower:
                return f"The {tag_lower} color appears in the flag design or background."
            elif "sign" in desc_lower:
                return f"The {tag_lower} color is visible on signs or signage."
            else:
                return f"The {tag_lower} color is prominently displayed in the image."
        
        elif tag_lower in ['elephant']:
            if "emblem" in desc_lower or "symbol" in desc_lower:
                return "Elephant features appear in sculptural or symbolic form, possibly in an emblem or carved design."
            else:
                return "Elephant-like characteristics are visible, potentially in artistic or symbolic representation."
        
        elif tag_lower in ['lion']:
            if "emblem" in desc_lower or "symbol" in desc_lower:
                return "Lion features are present in sculptural form, likely as part of an official emblem or carved symbol."
            else:
                return "Lion-like features are visible in the image."
        
        elif tag_lower in ['stop', 'sign', 'signs']:
            return "Traffic or informational signage with text and symbols is visible."
        
        elif tag_lower in ['pole', 'post']:
            return "Vertical support structures are present, likely supporting signs or other elements."
        
        elif tag_lower in ['gold', 'golden']:
            if "emblem" in desc_lower:
                return "Golden or yellow-colored elements appear in emblematic or decorative features."
            else:
                return "Gold or golden coloring is visible in decorative elements."
        
        else:
            return f"Visual elements associated with {tag} are present in the image."
    
    def is_still_generic(self, text: str) -> bool:
        """Check if explanation is still too generic"""
        generic_phrases = [
            "distinctive visual characteristics",
            "can be identified",
            "is present",
            "are visible",
            "element can be",
            "prominently visible"
        ]
        
        text_lower = text.lower()
        return any(phrase in text_lower for phrase in generic_phrases) and len(text) < 50
    
    def extract_clean_text(self, full_response: str, prompt: str) -> str:
        """Extract and clean generated text, preserving meaningful content"""
        try:
            # Remove prompt
            if prompt in full_response:
                generated = full_response.replace(prompt, "").strip()
            else:
                generated = full_response.strip()
            
            # Clean special tokens but preserve content
            generated = re.sub(r'<[^>]+>', '', generated)
            generated = re.sub(r'\s+', ' ', generated)
            
            # Remove only the specific noise pattern we know about
            if '. the, to and' in generated.lower():
                return ""
            
            # Basic validation - be less aggressive
            generated = generated.strip()
            if len(generated) < 5:
                return ""
            
            # Remove obvious repetitive garbage
            words = generated.split()
            if len(words) > 5 and len(set(words)) < len(words) // 3:
                return ""  # Too repetitive
            
            # Limit length but preserve content
            if len(generated) > 250:
                sentences = re.split(r'[.!?]+', generated)
                if sentences and len(sentences[0]) > 20:
                    return sentences[0].strip() + "."
                else:
                    return generated[:250] + "..."
            
            return generated
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error cleaning text: {e}")
            return ""

# Initialize the explainer
logger.info("üîÑ Initializing Kosmos-2 Explainer...")
kosmos_explainer = Kosmos2Explainer()
print("‚úÖ Kosmos-2 Explainer initialized successfully!")

"""
Cell 3: PDF Scanner and Parser
Scan PDF reports and extract image information and tags
"""

class PDFAnalysisScanner:
    """Scanner for PDF reports generated by the image tagging system"""
    
    def __init__(self):
        self.supported_formats = {'.pdf'}
        # Extended image format support
        self.image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp', '.gif'}
    
    def scan_pdf_report(self, pdf_path: str) -> List[Dict[str, Any]]:
        """
        Enhanced PDF scanning with better image extraction and format support
        """
        try:
            pdf_path = Path(pdf_path)
            if not pdf_path.exists():
                raise FileNotFoundError(f"PDF file not found: {pdf_path}")
            
            if pdf_path.suffix.lower() not in self.supported_formats:
                raise ValueError(f"Unsupported file format: {pdf_path.suffix}")
            
            logger.info(f"üìñ Scanning PDF report: {pdf_path.name}")
            
            # Check if fitz is available
            if fitz is None:
                raise ImportError("PyMuPDF (fitz) is not available. Please install it: pip install PyMuPDF")
            
            # Open PDF document
            doc = fitz.open(str(pdf_path))
            extracted_data = []
            
            logger.info(f"üìÑ PDF has {len(doc)} pages")
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                logger.info(f"üîç Processing page {page_num + 1}/{len(doc)}")
                
                # Extract text from page
                text = page.get_text()
                
                # Extract images from page with better handling
                image_list = page.get_images(full=True)  # Get full image info
                logger.info(f"üì∑ Found {len(image_list)} images on page {page_num + 1}")
                
                # Parse text for image information
                image_info = self._parse_page_text(text, page_num)
                
                # Extract actual images with enhanced error handling
                for img_index, img in enumerate(image_list):
                    try:
                        # Get image reference
                        xref = img[0]
                        
                        # Get image dictionary for better handling
                        img_dict = doc.extract_image(xref)
                        img_data = img_dict["image"]
                        img_ext = img_dict["ext"]
                        
                        logger.info(f"üñºÔ∏è Processing image {img_index + 1}: format={img_ext}")
                        
                        # Create PIL Image from raw data
                        img_pil = Image.open(io.BytesIO(img_data))
                        
                        # Skip images that are too small (likely UI elements or decorations)
                        if img_pil.width < 100 or img_pil.height < 100:
                            logger.info(f"‚è© Skipping small image ({img_pil.width}x{img_pil.height})")
                            continue
                        
                        # Skip images that are too large (likely full page scans)
                        if img_pil.width > 3000 or img_pil.height > 3000:
                            logger.info(f"‚è© Skipping very large image ({img_pil.width}x{img_pil.height}) - likely page scan")
                            continue
                        
                        # Convert to RGB if needed for consistency
                        if img_pil.mode != 'RGB':
                            if img_pil.mode in ['RGBA', 'LA']:
                                # Handle alpha channels
                                background = Image.new('RGB', img_pil.size, (255, 255, 255))
                                if img_pil.mode == 'RGBA':
                                    background.paste(img_pil, mask=img_pil.split()[-1])
                                else:
                                    background.paste(img_pil, mask=img_pil.split()[-1])
                                img_pil = background
                            else:
                                # Convert other modes to RGB
                                img_pil = img_pil.convert('RGB')
                        
                        # Ensure reasonable size for processing
                        max_size = 1024
                        if max(img_pil.width, img_pil.height) > max_size:
                            img_pil.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                            logger.info(f"üìè Resized image to {img_pil.size} for processing")
                        
                        logger.info(f"‚úÖ Successfully extracted image {img_index + 1}: {img_pil.size}, mode={img_pil.mode}")
                        
                        # Store image with parsed information
                        image_record = {
                            "page_number": page_num + 1,
                            "image_index": img_index + 1,
                            "image": img_pil,
                            "extracted_info": image_info,
                            "image_data": img_data,
                            "image_size": img_pil.size,
                            "original_format": img_ext,
                            "extraction_method": "fitz_extract_image"
                        }
                        extracted_data.append(image_record)
                        
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Failed to extract image {img_index + 1} from page {page_num + 1}: {e}")
                        
                        # Try alternative extraction method
                        try:
                            logger.info(f"üîÑ Trying alternative extraction for image {img_index + 1}")
                            pix = fitz.Pixmap(doc, xref)
                            
                            if pix.width < 100 or pix.height < 100:
                                pix = None
                                continue
                            
                            # Convert to RGB if needed
                            if pix.n - pix.alpha < 4:  # GRAY or RGB
                                if pix.n - pix.alpha == 1:  # GRAY
                                    pix_rgb = fitz.Pixmap(fitz.csRGB, pix)
                                    pix = None
                                    pix = pix_rgb
                                
                                img_data_alt = pix.tobytes("png")
                                img_pil_alt = Image.open(io.BytesIO(img_data_alt))
                                
                                if img_pil_alt.mode != 'RGB':
                                    img_pil_alt = img_pil_alt.convert('RGB')
                                
                                logger.info(f"‚úÖ Alternative extraction successful: {img_pil_alt.size}")
                                
                                image_record = {
                                    "page_number": page_num + 1,
                                    "image_index": img_index + 1,
                                    "image": img_pil_alt,
                                    "extracted_info": image_info,
                                    "image_data": img_data_alt,
                                    "image_size": img_pil_alt.size,
                                    "original_format": "png",
                                    "extraction_method": "fitz_pixmap_fallback"
                                }
                                extracted_data.append(image_record)
                            
                            if pix:
                                pix = None
                                
                        except Exception as e2:
                            logger.error(f"‚ùå Both extraction methods failed for image {img_index + 1}: {e2}")
                            continue
            
            doc.close()
            
            logger.info(f"‚úÖ Successfully extracted {len(extracted_data)} valid images from PDF")
            
            if len(extracted_data) == 0:
                logger.warning("‚ö†Ô∏è No images were extracted from the PDF")
                logger.info("üí° Possible reasons:")
                logger.info("   ‚Ä¢ PDF doesn't contain embedded images")
                logger.info("   ‚Ä¢ Images are too small (< 100x100 pixels)")
                logger.info("   ‚Ä¢ Images are in unsupported format")
                logger.info("   ‚Ä¢ PDF is corrupted or password protected")
                logger.info("   ‚Ä¢ Images are vector graphics (not supported)")
            else:
                # Show extraction summary
                formats = {}
                for record in extracted_data:
                    fmt = record.get('original_format', 'unknown')
                    formats[fmt] = formats.get(fmt, 0) + 1
                
                logger.info(f"üìä Extraction summary: {dict(formats)}")
            
            return extracted_data
            
        except Exception as e:
            logger.error(f"‚ùå Failed to scan PDF: {e}")
            return []
    
    def _parse_page_text(self, text: str, page_num: int) -> Dict[str, Any]:
        """
        Parse page text to extract image information and tags
        """
        try:
            info = {
                "page_number": page_num + 1,
                "file_name": None,
                "file_path": None,
                "ai_tags": [],
                "blip_caption": None,
                "llava_description": None,
                "file_info": {}
            }
            
            lines = text.split('\n')
            current_section = None
            
            for line in lines:
                line = line.strip()
                
                # Extract image title/filename
                if line.startswith("Image") and ":" in line:
                    parts = line.split(":", 1)
                    if len(parts) > 1:
                        info["file_name"] = parts[1].strip()
                
                # Extract file path
                if "Path:" in line:
                    info["file_path"] = line.replace("Path:", "").strip().replace("‚Ä¢", "").strip()
                
                # Extract image dimensions
                if "Size:" in line:
                    size_info = line.replace("Size:", "").strip().replace("‚Ä¢", "").strip()
                    info["file_info"]["dimensions"] = size_info
                
                # Extract format
                if "Format:" in line:
                    format_info = line.replace("Format:", "").strip().replace("‚Ä¢", "").strip()
                    info["file_info"]["format"] = format_info
                
                # Extract AI-generated tags
                if "AI-Generated Tags:" in line:
                    current_section = "tags"
                    continue
                
                if current_section == "tags" and line.startswith("‚Ä¢"):
                    tag = line.replace("‚Ä¢", "").strip()
                    if tag and tag not in info["ai_tags"]:
                        info["ai_tags"].append(tag)
                
                # Extract BLIP caption
                if "BLIP Caption:" in line:
                    current_section = "blip"
                    continue
                
                if current_section == "blip" and line and not line.startswith("‚Ä¢") and ":" not in line:
                    info["blip_caption"] = line
                    current_section = None
                
                # Extract LLaVA description
                if "LLaVA Description:" in line:
                    current_section = "llava"
                    continue
                
                if current_section == "llava" and line and not line.startswith("‚Ä¢") and ":" not in line:
                    info["llava_description"] = line
                    current_section = None
                
                # Reset section on new headers
                if any(header in line for header in ["File Information:", "AI-Generated Tags:", "BLIP Caption:", "LLaVA Description:"]):
                    if "AI-Generated Tags:" not in line:
                        current_section = None
            
            return info
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to parse page text: {e}")
            return {}
    
    def find_pdf_reports(self, directory: str) -> List[str]:
        """
        Find all PDF reports in a directory
        """
        try:
            directory = Path(directory)
            pdf_files = []
            
            # Look for PDF files that match the naming pattern
            patterns = [
                "*image_analysis_report*.pdf",
                "*ai_image_analysis_report*.pdf",
                "*single_image_report*.pdf"
            ]
            
            for pattern in patterns:
                pdf_files.extend(directory.glob(pattern))
            
            # Also include any PDF files in the directory
            all_pdfs = list(directory.glob("*.pdf"))
            
            # Combine and remove duplicates
            all_found = list(set(pdf_files + all_pdfs))
            
            logger.info(f"üìÅ Found {len(all_found)} PDF files in {directory}")
            return [str(pdf) for pdf in all_found]
            
        except Exception as e:
            logger.error(f"‚ùå Failed to find PDF reports: {e}")
            return []

# Initialize PDF scanner
pdf_scanner = PDFAnalysisScanner()
print("‚úÖ PDF Scanner initialized successfully!")

"""
Cell 4: Simplified Explainable AI Analyzer (PDF Image Extraction Only)
Main analyzer that extracts images from PDF and uses Kosmos-2 for explanations
"""

class ExplainableImageTagAnalyzer:
    """
    Simplified analyzer that extracts images from PDF and generates explanations using Kosmos-2
    """
    
    def __init__(self):
        self.kosmos_explainer = kosmos_explainer
        self.pdf_scanner = pdf_scanner
        self.analysis_results = []
    
    def analyze_pdf_report_direct(self, pdf_path: str) -> List[Dict[str, Any]]:
        """
        Analyze PDF report by extracting images directly and generating explanations
        """
        try:
            logger.info(f"üîç Starting direct PDF analysis with image extraction...")
            logger.info(f"üìÑ PDF Path: {pdf_path}")
            
            # 1. Scan PDF and extract images with their information
            extracted_images = self.pdf_scanner.scan_pdf_report(pdf_path)
            
            if not extracted_images:
                logger.warning("‚ö†Ô∏è No images found in PDF report")
                return []
            
            logger.info(f"üìä Found {len(extracted_images)} images to analyze")
            
            # 2. Generate explanations for each extracted image
            results = []
            
            for i, image_data in enumerate(extracted_images, 1):
                logger.info(f"üî¨ Analyzing image {i}/{len(extracted_images)}")
                
                try:
                    # Extract information
                    extracted_image = image_data["image"]  # PIL Image from PDF
                    extracted_info = image_data["extracted_info"]
                    existing_tags = extracted_info.get("ai_tags", [])
                    pdf_filename = extracted_info.get("file_name", f"Image_{i}")
                    
                    if not existing_tags:
                        logger.warning(f"‚ö†Ô∏è No tags found for image {i}, skipping...")
                        continue
                    
                    # Generate explanations using Kosmos-2 on the extracted PDF image
                    logger.info(f"ü§ñ Generating Kosmos-2 explanations for {len(existing_tags)} tags...")
                    explanations = self.kosmos_explainer.generate_explanation(extracted_image, existing_tags)
                    
                    # Compile analysis result
                    analysis_result = {
                        "image_index": i,
                        "page_number": image_data["page_number"],
                        "file_name": pdf_filename,
                        "file_path": extracted_info.get("file_path", "Unknown"),
                        "original_tags": existing_tags,
                        "blip_caption": extracted_info.get("blip_caption"),
                        "llava_description": extracted_info.get("llava_description"),
                        "kosmos_explanations": explanations,
                        "analysis_timestamp": datetime.now().isoformat(),
                        "extracted_image_object": extracted_image,  # The image extracted from PDF
                        "extraction_info": {
                            "extraction_method": image_data.get("extraction_method", "unknown"),
                            "image_size": image_data.get("image_size", "unknown"),
                            "original_format": image_data.get("original_format", "unknown")
                        }
                    }
                    
                    results.append(analysis_result)
                    
                    logger.info(f"‚úÖ Generated explanations for {len(existing_tags)} tags")
                    
                except Exception as e:
                    logger.error(f"‚ùå Failed to analyze image {i}: {e}")
                    continue
            
            self.analysis_results = results
            logger.info(f"üéâ Direct analysis complete! Generated explanations for {len(results)} images")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Failed to analyze PDF report directly: {e}")
            return []
    
    def get_tag_explanation(self, image_index: int, tag: str) -> str:
        """
        Get explanation for a specific tag on a specific image
        """
        try:
            if not self.analysis_results:
                return "No analysis results available"
            
            # Find the image analysis
            for result in self.analysis_results:
                if result["image_index"] == image_index:
                    tag_explanations = result["kosmos_explanations"].get("tag_explanations", {})
                    return tag_explanations.get(tag, f"No explanation found for tag '{tag}'")
            
            return f"Image {image_index} not found in analysis results"
            
        except Exception as e:
            logger.error(f"‚ùå Failed to get tag explanation: {e}")
            return f"Error retrieving explanation: {e}"
    
    def generate_summary_statistics(self) -> Dict[str, Any]:
        """
        Generate summary statistics of the analysis
        """
        try:
            if not self.analysis_results:
                return {}
            
            stats = {
                "total_images_analyzed": len(self.analysis_results),
                "total_tags_explained": 0,
                "average_tags_per_image": 0,
                "most_common_tags": {},
                "explanation_confidence": [],
                "processing_timestamp": datetime.now().isoformat(),
                "analysis_method": "direct_pdf_extraction"
            }
            
            all_tags = []
            total_tags = 0
            
            for result in self.analysis_results:
                tags = result["original_tags"]
                all_tags.extend(tags)
                total_tags += len(tags)
            
            stats["total_tags_explained"] = total_tags
            stats["average_tags_per_image"] = round(total_tags / len(self.analysis_results), 2)
            
            # Count tag frequency
            tag_counts = {}
            for tag in all_tags:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
            
            # Get most common tags
            sorted_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)
            stats["most_common_tags"] = dict(sorted_tags[:10])
            
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå Failed to generate summary statistics: {e}")
            return {}
    
    def save_results_to_json(self, output_path: str = None) -> str:
        """
        Save analysis results to JSON file
        """
        try:
            if output_path is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_path = f"direct_explainable_ai_analysis_{timestamp}.json"
            
            # Prepare data for JSON (remove image objects)
            json_data = {
                "analysis_metadata": {
                    "total_images": len(self.analysis_results),
                    "analysis_timestamp": datetime.now().isoformat(),
                    "model_used": "microsoft/kosmos-2-patch14-224",
                    "analysis_method": "direct_pdf_extraction",
                    "features": ["pdf_image_extraction", "explainable_ai"]
                },
                "summary_statistics": self.generate_summary_statistics(),
                "image_analyses": []
            }
            
            for result in self.analysis_results:
                # Remove image object for JSON serialization
                json_result = {k: v for k, v in result.items() if k != "extracted_image_object"}
                json_data["image_analyses"].append(json_result)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"üíæ Direct analysis results saved to: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå Failed to save results to JSON: {e}")
            return ""

# Initialize the simplified explainable analyzer
explainable_analyzer = ExplainableImageTagAnalyzer()
print("‚úÖ Simplified Explainable AI Analyzer (Direct PDF Extraction) initialized!")

"""
Cell 5: Simplified Explainable AI Report Generator (PDF Images Only)
Generate comprehensive PDF reports with explanations using extracted PDF images
"""

class ExplainableAIReportGenerator:
    """
    Generate PDF reports with explainable AI analysis using images extracted from PDF
    """
    
    def __init__(self):
        self.styles = getSampleStyleSheet()
        self.title_style = ParagraphStyle(
            'ExplainableTitle',
            parent=self.styles['Heading1'],
            fontSize=26,
            spaceAfter=30,
            textColor=colors.darkblue,
            alignment=1  # Center alignment
        )
        self.section_style = ParagraphStyle(
            'SectionHeading',
            parent=self.styles['Heading2'],
            fontSize=18,
            spaceAfter=15,
            textColor=colors.darkgreen
        )
        self.subsection_style = ParagraphStyle(
            'SubsectionHeading',
            parent=self.styles['Heading3'],
            fontSize=14,
            spaceAfter=10,
            textColor=colors.darkred
        )
        self.explanation_style = ParagraphStyle(
            'ExplanationStyle',
            parent=self.styles['Normal'],
            fontSize=11,
            leftIndent=20,
            rightIndent=20,
            spaceAfter=8,
            textColor=colors.black
        )
        self.tag_style = ParagraphStyle(
            'TagExplanationStyle',
            parent=self.styles['Normal'],
            fontSize=10,
            leftIndent=30,
            textColor=colors.blue,
            spaceAfter=5
        )
    
    def create_explainable_report(self, analysis_results: List[Dict[str, Any]], 
                                output_path: str = None) -> str:
        """
        Create comprehensive explainable AI report using PDF-extracted images
        """
        try:
            if output_path is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_path = f"explainable_ai_report_{timestamp}.pdf"
            
            logger.info(f"üìä Generating explainable AI report with PDF-extracted images...")
            
            doc = SimpleDocTemplate(output_path, pagesize=A4)
            story = []
            
            # Title page
            story.append(Paragraph("Explainable AI Image Tagging Report", self.title_style))
            story.append(Paragraph("Generated using Kosmos-2 Vision-Language Model", self.styles['Normal']))
            story.append(Paragraph("Images extracted directly from PDF report", self.styles['Normal']))
            story.append(Spacer(1, 30))
            
            # Executive summary
            story.append(Paragraph("Executive Summary", self.section_style))
            
            # Generate statistics
            stats = self._generate_statistics(analysis_results)
            
            summary_data = [
                ['Total Images Analyzed:', str(stats['total_images'])],
                ['Total Tags Explained:', str(stats['total_tags'])],
                ['Average Tags per Image:', str(stats['avg_tags'])],
                ['Most Common Tag:', stats['most_common_tag']],
                ['Analysis Model:', 'Kosmos-2 (microsoft/kosmos-2-patch14-224)'],
                ['Image Source:', 'Extracted from PDF Report'],
                ['Report Generated:', datetime.now().strftime('%Y-%m-%d %H:%M:%S')]
            ]
            
            summary_table = Table(summary_data, colWidths=[3*inch, 3*inch])
            summary_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, -1), colors.lightblue),
                ('TEXTCOLOR', (0, 0), (-1, -1), colors.black),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 11),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 12),
                ('GRID', (0, 0), (-1, -1), 1, colors.darkblue)
            ]))
            
            story.append(summary_table)
            story.append(PageBreak())
            
            # Methodology section
            story.append(Paragraph("Methodology", self.section_style))
            methodology_text = """
            This report provides explainable AI analysis of image tagging results using Microsoft's Kosmos-2 
            vision-language model. The analysis process includes:
            
            1. Direct extraction of images from the PDF report
            2. Parsing of existing AI-generated tags from the PDF content
            3. Feature-based explanations using Kosmos-2 for why each tag was assigned
            4. Visual confidence assessment of identified elements
            
            The analysis helps understand the reasoning behind AI-generated tags by providing detailed 
            explanations of the visual features that led to each tag assignment, improving transparency 
            and trust in automated image tagging systems.
            """
            story.append(Paragraph(methodology_text, self.styles['Normal']))
            story.append(Spacer(1, 20))
            
            # Individual image analyses
            story.append(Paragraph("Detailed Image Analyses with Kosmos-2 Explanations", self.section_style))
            story.append(PageBreak())
            
            for i, result in enumerate(analysis_results, 1):
                try:
                    # Image header
                    story.append(Paragraph(f"Analysis {i}: {result['file_name']}", self.section_style))
                    story.append(Spacer(1, 10))
                    
                    # Create content table with image and analysis
                    content_data = []
                    
                    # Image section - show the extracted PDF image
                    image_content = []
                    
                    # PDF-extracted Image with improved handling
                    if "extracted_image_object" in result:
                        try:
                            img = result["extracted_image_object"]
                            # Create a copy to avoid modifying original
                            img_copy = img.copy()
                            img_copy.thumbnail((280, 280), Image.Resampling.LANCZOS)
                            
                            img_buffer = io.BytesIO()
                            img_copy.save(img_buffer, format='PNG', quality=95)
                            img_buffer.seek(0)
                            
                            from reportlab.platypus import Image as RLImage
                            image_content.append(Paragraph("<b>Extracted Image:</b>", self.styles['Normal']))
                            image_content.append(RLImage(img_buffer, width=2.5*inch, height=2.5*inch))
                            
                            # Add extraction info
                            extraction_info = result.get("extraction_info", {})
                            if extraction_info:
                                image_content.append(Spacer(1, 5))
                                image_content.append(Paragraph(f"<b>Extraction Details:</b>", self.styles['Normal']))
                                image_content.append(Paragraph(f"Size: {extraction_info.get('image_size', 'Unknown')}", self.styles['Normal']))
                                image_content.append(Paragraph(f"Method: {extraction_info.get('extraction_method', 'Unknown')}", self.styles['Normal']))
                                image_content.append(Paragraph(f"Format: {extraction_info.get('original_format', 'Unknown')}", self.styles['Normal']))
                            
                        except Exception as e:
                            logger.error(f"‚ùå Image display error: {e}")
                            image_content.append(Paragraph("<b>Extracted Image:</b>", self.styles['Normal']))
                            image_content.append(Paragraph(f"[Error displaying image: {str(e)[:50]}...]", self.styles['Normal']))
                    else:
                        image_content.append(Paragraph("<b>Extracted Image:</b>", self.styles['Normal']))
                        image_content.append(Paragraph("[Image not available]", self.styles['Normal']))
                    
                    # Analysis content column
                    analysis_content = []
                    
                    # Basic information
                    analysis_content.append(Paragraph("<b>Image Information:</b>", self.styles['Normal']))
                    analysis_content.append(Paragraph(f"File: {result.get('file_path', 'Unknown')}", self.styles['Normal']))
                    analysis_content.append(Paragraph(f"Page: {result.get('page_number', 'Unknown')}", self.styles['Normal']))
                    analysis_content.append(Paragraph(f"Index: {result.get('image_index', 'Unknown')}", self.styles['Normal']))
                    analysis_content.append(Spacer(1, 10))
                    
                    # Original tags with better formatting
                    analysis_content.append(Paragraph("<b>Original AI-Generated Tags:</b>", self.styles['Normal']))
                    original_tags = result.get('original_tags', [])
                    if original_tags:
                        # Group tags in lines of 6 for better readability
                        tag_lines = []
                        for j in range(0, len(original_tags), 6):
                            tag_group = original_tags[j:j+6]
                            tag_lines.append(", ".join(tag_group))
                        
                        for line in tag_lines[:3]:  # Show first 3 lines (18 tags max)
                            analysis_content.append(Paragraph(f"‚Ä¢ {line}", self.tag_style))
                        
                        if len(original_tags) > 18:
                            remaining = len(original_tags) - 18
                            analysis_content.append(Paragraph(f"‚Ä¢ ... and {remaining} more tags", self.tag_style))
                    else:
                        analysis_content.append(Paragraph("No tags found", self.styles['Normal']))
                    
                    analysis_content.append(Spacer(1, 10))
                    
                    # Kosmos-2 general description
                    kosmos_explanations = result.get('kosmos_explanations', {})
                    general_desc = kosmos_explanations.get('general_description', '')
                    if general_desc and general_desc not in ["Clear visual elements identified", "Unable to analyze visual features"]:
                        analysis_content.append(Paragraph("<b>Kosmos-2 Visual Analysis:</b>", self.styles['Normal']))
                        # Limit description length for report
                        if len(general_desc) > 150:
                            general_desc = general_desc[:150] + "..."
                        analysis_content.append(Paragraph(general_desc, self.explanation_style))
                    
                    # Create the main table with image and analysis
                    content_data = [[image_content, analysis_content]]
                    
                    main_table = Table(content_data, colWidths=[3.5*inch, 3.5*inch])
                    main_table.setStyle(TableStyle([
                        ('VALIGN', (0, 0), (-1, -1), 'TOP'),
                        ('LEFTPADDING', (0, 0), (-1, -1), 10),
                        ('RIGHTPADDING', (0, 0), (-1, -1), 10),
                        ('TOPPADDING', (0, 0), (-1, -1), 10),
                        ('BOTTOMPADDING', (0, 0), (-1, -1), 10),
                        ('GRID', (0, 0), (-1, -1), 1, colors.lightgrey)
                    ]))
                    
                    story.append(main_table)
                    story.append(Spacer(1, 15))
                    
                    # Feature-based tag explanations
                    tag_explanations = kosmos_explanations.get('tag_explanations', {})
                    if tag_explanations:
                        story.append(Paragraph("Feature-Based Tag Explanations:", self.subsection_style))
                        
                        # Show explanations for the most important tags
                        explained_count = 0
                        for tag, explanation in tag_explanations.items():
                            if explained_count >= 12:  # Limit to 12 detailed explanations
                                break
                            
                            if explanation and len(explanation.strip()) > 25:  # Only show meaningful explanations
                                story.append(Paragraph(f"<b>'{tag}':</b> {explanation}", self.explanation_style))
                                explained_count += 1
                        
                        remaining_tags = len(tag_explanations) - explained_count
                        if remaining_tags > 0:
                            story.append(Paragraph(f"<i>... and {remaining_tags} more tag explanations available</i>", 
                                                 self.styles['Normal']))
                    
                    # Confidence assessment
                    confidence = kosmos_explanations.get('confidence_assessment', '')
                    if confidence and confidence not in ["Clear visual elements detected", "Image features are clearly identifiable"]:
                        story.append(Spacer(1, 10))
                        story.append(Paragraph("Visual Quality Assessment:", self.subsection_style))
                        story.append(Paragraph(confidence, self.explanation_style))
                    
                    # Original model outputs for reference
                    story.append(Spacer(1, 15))
                    story.append(Paragraph("Original Model Outputs (Reference):", self.subsection_style))
                    
                    if result.get('blip_caption'):
                        caption = result['blip_caption']
                        if len(caption) > 120:
                            caption = caption[:120] + "..."
                        story.append(Paragraph(f"<b>BLIP Caption:</b> {caption}", self.styles['Normal']))
                    
                    if result.get('llava_description'):
                        llava_desc = result['llava_description']
                        if len(llava_desc) > 180:
                            llava_desc = llava_desc[:180] + "..."
                        story.append(Paragraph(f"<b>LLaVA Description:</b> {llava_desc}", self.styles['Normal']))
                    
                    story.append(PageBreak())
                    
                except Exception as e:
                    logger.error(f"‚ùå Error processing analysis {i}: {e}")
                    story.append(Paragraph(f"Error processing analysis {i}: {result.get('file_name', 'Unknown')}", 
                                         self.styles['Normal']))
                    story.append(Spacer(1, 20))
            
            # Insights and conclusions
            story.append(Paragraph("Key Insights & Analysis Summary", self.section_style))
            insights = self._generate_insights(analysis_results)
            for insight in insights:
                story.append(Paragraph(f"‚Ä¢ {insight}", self.styles['Normal']))
                story.append(Spacer(1, 5))
            
            # Build the PDF
            doc.build(story)
            logger.info(f"‚úÖ Explainable AI report generated: {output_path}")
            
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå Failed to create explainable report: {e}")
            return ""
    
    def _generate_statistics(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate summary statistics"""
        if not results:
            return {'total_images': 0, 'total_tags': 0, 'avg_tags': 0, 'most_common_tag': 'None'}
        
        total_images = len(results)
        all_tags = []
        
        for result in results:
            if result and isinstance(result, dict):
                all_tags.extend(result.get('original_tags', []))
        
        total_tags = len(all_tags)
        avg_tags = round(total_tags / total_images, 1) if total_images > 0 else 0
        
        # Find most common tag
        tag_counts = {}
        for tag in all_tags:
            if tag:  # Ensure tag is not None or empty
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        most_common_tag = max(tag_counts, key=tag_counts.get) if tag_counts else 'None'
        
        return {
            'total_images': total_images,
            'total_tags': total_tags,
            'avg_tags': avg_tags,
            'most_common_tag': most_common_tag
        }
    
    def _generate_insights(self, results: List[Dict[str, Any]]) -> List[str]:
        """Generate key insights from the analysis"""
        insights = []
        
        if not results:
            insights.append("No analysis results available for insight generation.")
            return insights
        
        # Tag frequency analysis
        all_tags = []
        for result in results:
            all_tags.extend(result.get('original_tags', []))
        
        if all_tags:
            tag_counts = {}
            for tag in all_tags:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
            
            most_common = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:3]
            insights.append(f"Most frequently identified elements: {', '.join([f'{tag}({count})' for tag, count in most_common])}")
        
        # Explanation quality analysis
        explanations_with_content = 0
        for result in results:
            kosmos_explanations = result.get('kosmos_explanations', {})
            if kosmos_explanations.get('general_description') and len(kosmos_explanations.get('general_description', '')) > 25:
                explanations_with_content += 1
        
        if explanations_with_content > 0:
            insights.append(f"Kosmos-2 provided detailed explanations for {explanations_with_content}/{len(results)} images ({round(100*explanations_with_content/len(results), 1)}%)")
        
        # Tag explanation coverage
        total_tag_explanations = 0
        total_tags = 0
        for result in results:
            tags = result.get('original_tags', [])
            tag_explanations = result.get('kosmos_explanations', {}).get('tag_explanations', {})
            total_tags += len(tags)
            total_tag_explanations += len([exp for exp in tag_explanations.values() if exp and len(exp) > 20])
        
        if total_tags > 0:
            coverage = round(100 * total_tag_explanations / total_tags, 1)
            insights.append(f"Meaningful tag explanation coverage: {coverage}% ({total_tag_explanations}/{total_tags} tags with detailed explanations)")
        
        insights.append("Images were extracted directly from the PDF report, ensuring perfect correspondence between tags and visual content.")
        insights.append("Kosmos-2 provides grounded visual reasoning, explaining tag assignments based on observable image features.")
        insights.append("This direct extraction approach eliminates dataset matching issues and provides reliable explainable AI analysis.")
        
        return insights

# Initialize simplified report generator
report_generator = ExplainableAIReportGenerator()
print("‚úÖ Simplified Explainable AI Report Generator (PDF Images Only) initialized!")

"""
Cell 6: Simplified Main Interface (PDF Only)
Command-line interface for explainable AI analysis using direct PDF extraction
"""

class ExplainableAICommandInterface:
    """
    Simplified command-line interface for explainable AI system using PDF extraction only
    """
    
    def __init__(self):
        self.analyzer = explainable_analyzer
        self.report_generator = report_generator
        self.pdf_scanner = pdf_scanner
    
    def run_direct_analysis(self, pdf_path: str, output_dir: str = None) -> Dict[str, str]:
        """
        Run explainable AI analysis by extracting images directly from PDF
        """
        try:
            logger.info(f"üöÄ Starting direct PDF analysis...")
            logger.info(f"üìÑ PDF Path: {pdf_path}")
            
            # Validate input
            if not os.path.exists(pdf_path):
                raise FileNotFoundError(f"PDF file not found: {pdf_path}")
            
            # Set output directory
            if output_dir is None:
                output_dir = Path(pdf_path).parent
            else:
                output_dir = Path(output_dir)
                output_dir.mkdir(parents=True, exist_ok=True)
            
            # 1. Analyze PDF report with direct image extraction
            logger.info("üìä Step 1: Extracting images from PDF and analyzing with Kosmos-2...")
            analysis_results = self.analyzer.analyze_pdf_report_direct(pdf_path)
            
            if not analysis_results:
                raise ValueError("No analysis results generated. Please check the PDF format and content.")
            
            # 2. Generate JSON results
            logger.info("üíæ Step 2: Saving analysis results to JSON...")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            json_path = output_dir / f"direct_explainable_analysis_{timestamp}.json"
            saved_json = self.analyzer.save_results_to_json(str(json_path))
            
            # 3. Generate explainable AI report
            logger.info("üìã Step 3: Generating explainable AI PDF report...")
            report_path = output_dir / f"explainable_ai_report_{timestamp}.pdf"
            saved_report = self.report_generator.create_explainable_report(
                analysis_results, str(report_path)
            )
            
            # 4. Generate summary
            stats = self.analyzer.generate_summary_statistics()
            
            results = {
                "status": "success",
                "pdf_analyzed": pdf_path,
                "images_processed": len(analysis_results),
                "json_output": saved_json,
                "report_output": saved_report,
                "analysis_timestamp": timestamp,
                "statistics": stats
            }
            
            logger.info("üéâ Direct analysis complete!")
            logger.info(f"üìä Processed {len(analysis_results)} images from PDF")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Direct analysis failed: {e}")
            return {
                "status": "error",
                "error_message": str(e),
                "pdf_analyzed": pdf_path
            }
    
    def find_and_analyze_reports(self, directory: str) -> List[Dict[str, str]]:
        """
        Find all PDF reports in a directory and analyze them
        """
        try:
            logger.info(f"üîç Searching for PDF reports in: {directory}")
            
            pdf_files = self.pdf_scanner.find_pdf_reports(directory)
            
            if not pdf_files:
                logger.warning("‚ö†Ô∏è No PDF files found in directory")
                return []
            
            logger.info(f"üìÅ Found {len(pdf_files)} PDF files")
            
            results = []
            for i, pdf_path in enumerate(pdf_files, 1):
                logger.info(f"üìä Processing PDF {i}/{len(pdf_files)}: {Path(pdf_path).name}")
                
                result = self.run_direct_analysis(pdf_path, directory)
                result["pdf_index"] = i
                result["total_pdfs"] = len(pdf_files)
                results.append(result)
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Failed to find and analyze reports: {e}")
            return []
    
    def interactive_mode(self):
        """
        Simplified interactive command-line mode
        """
        print("\n" + "="*70)
        print("üî¨ EXPLAINABLE AI IMAGE TAGGING ANALYZER")
        print("   Powered by Kosmos-2 Vision-Language Model")
        print("   üìÑ Direct PDF image extraction - No dataset required!")
        print("="*70)
        
        while True:
            try:
                print("\nüìã Available Commands:")
                print("  1. analyze                               - Analyze single PDF report")
                print("  2. scan                                  - Analyze all PDFs in directory")
                print("  3. status                                - Show system status")
                print("  4. help                                  - Show detailed help")
                print("  5. quit                                  - Exit program")
                
                command = input("\nüî¨ explainable-ai> ").strip().lower()
                
                if not command:
                    continue
                
                if command in ['quit', 'exit', 'q']:
                    print("üëã Goodbye!")
                    break
                
                elif command == 'analyze':
                    # Get PDF path
                    pdf_path = input("üìÑ Enter PDF report path: ").strip().strip('"\'')
                    if not pdf_path:
                        print("‚ùå PDF path cannot be empty!")
                        continue
                    
                    print(f"\nüî¨ Analyzing PDF: {pdf_path}")
                    
                    result = self.run_direct_analysis(pdf_path)
                    self._print_analysis_result(result)
                
                elif command == 'scan':
                    # Get directory path
                    directory = input("üìÇ Enter directory containing PDF reports: ").strip().strip('"\'')
                    if not directory:
                        print("‚ùå Directory path cannot be empty!")
                        continue
                    
                    print(f"\nüîç Scanning directory: {directory}")
                    
                    results = self.find_and_analyze_reports(directory)
                    self._print_batch_results(results)
                
                elif command == 'status':
                    self._print_system_status()
                
                elif command == 'help':
                    self._print_detailed_help()
                
                else:
                    print("‚ùå Invalid command.")
                    print("üí° Available commands: analyze, scan, status, help, quit")
                    
            except KeyboardInterrupt:
                print("\n\nüëã Interrupted by user. Goodbye!")
                break
            except Exception as e:
                print(f"‚ùå Error: {e}")
                logger.error(f"Interactive mode error: {e}")
    
    def _print_analysis_result(self, result: Dict[str, str]):
        """Print analysis result with detailed information"""
        print("\n" + "="*60)
        
        if result["status"] == "success":
            print("‚úÖ EXPLAINABLE AI ANALYSIS SUCCESSFUL")
            print(f"üìÑ PDF Analyzed: {result['pdf_analyzed']}")
            print(f"üñºÔ∏è  Images Processed: {result['images_processed']}")
            
            print(f"\nüìã Generated Files:")
            print(f"   üíæ JSON Results: {result['json_output']}")
            print(f"   üìä Explainable Report: {result['report_output']}")
            
            if "statistics" in result:
                stats = result["statistics"]
                print(f"\nüìä Statistics:")
                print(f"   ‚Ä¢ Total Tags Explained: {stats.get('total_tags_explained', 'N/A')}")
                print(f"   ‚Ä¢ Average Tags per Image: {stats.get('average_tags_per_image', 'N/A')}")
                
                if stats.get('most_common_tags'):
                    most_common = list(stats['most_common_tags'].items())[:3]
                    tags_str = ', '.join([f'{tag}({count})' for tag, count in most_common])
                    print(f"   ‚Ä¢ Most Common Tags: {tags_str}")
            
            print(f"\nüéØ Next Steps:")
            print(f"   1. Check the explainable AI PDF report for visual explanations")
            print(f"   2. Review the JSON file for detailed analysis data")
            print(f"   3. Use the insights to understand AI tagging decisions")
            
        else:
            print("‚ùå EXPLAINABLE AI ANALYSIS FAILED")
            print(f"üìÑ PDF: {result['pdf_analyzed']}")
            print(f"‚ùå Error: {result['error_message']}")
            
            # Provide troubleshooting tips
            print(f"\nüõ†Ô∏è Troubleshooting Tips:")
            if "not found" in result['error_message'].lower():
                print(f"   ‚Ä¢ Check if the PDF file exists")
                print(f"   ‚Ä¢ Use absolute paths instead of relative paths")
                print(f"   ‚Ä¢ Ensure proper file permissions")
            elif "pdf" in result['error_message'].lower():
                print(f"   ‚Ä¢ Verify the PDF is a valid image analysis report")
                print(f"   ‚Ä¢ Check if PDF contains embedded images")
                print(f"   ‚Ä¢ Ensure PDF is not corrupted or password protected")
            
        print("="*60)
    
    def _print_batch_results(self, results: List[Dict[str, str]]):
        """Print batch analysis results"""
        print("\n" + "="*60)
        print("üìä BATCH ANALYSIS RESULTS")
        print("="*60)
        
        successful = [r for r in results if r["status"] == "success"]
        failed = [r for r in results if r["status"] == "error"]
        
        print(f"‚úÖ Successful: {len(successful)}")
        print(f"‚ùå Failed: {len(failed)}")
        
        if successful:
            total_images = sum(r["images_processed"] for r in successful)
            
            print(f"üñºÔ∏è  Total Images Processed: {total_images}")
            
            print("\nüìã Generated Reports:")
            for result in successful:
                pdf_name = Path(result["pdf_analyzed"]).name
                print(f"   ‚Ä¢ {pdf_name} ‚Üí {result['images_processed']} images analyzed")
        
        if failed:
            print("\n‚ùå Failed Analyses:")
            for result in failed:
                pdf_name = Path(result["pdf_analyzed"]).name
                print(f"   ‚Ä¢ {pdf_name}: {result['error_message']}")
        
        print("="*60)
    
    def _print_system_status(self):
        """Print system status information"""
        print("\n" + "="*50)
        print("üîß SYSTEM STATUS")
        print("="*50)
        print(f"ü§ñ Kosmos-2 Model: Loaded")
        print(f"üíª Device: {kosmos_explainer.device}")
        print(f"üìÑ PDF Scanner: Ready")
        print(f"üìã Report Generator: Ready")
        print(f"üîó Analysis Mode: Direct PDF Extraction")
        print(f"üïí Current Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*50)
    
    def _print_detailed_help(self):
        """Print detailed help information"""
        print("\n" + "="*70)
        print("üìö DETAILED HELP")
        print("="*70)
        print("""
üî¨ EXPLAINABLE AI IMAGE TAGGING ANALYZER

This system analyzes PDF reports generated by the AI image tagging system
and provides explainable AI insights using Kosmos-2 with direct image extraction.

COMMANDS:
  analyze                  - Analyze a single PDF report
                            Example: Just type 'analyze' and enter the PDF path when prompted
  
  scan                     - Find and analyze all PDF reports in a directory
                            Example: Type 'scan' and enter the directory path when prompted
  
  status                   - Show current system status and configuration
  
  help                     - Show this detailed help information
  
  quit                     - Exit the program

SIMPLIFIED APPROACH:
‚Ä¢ NO dataset required - images are extracted directly from PDF
‚Ä¢ Eliminates dataset matching issues and complexities
‚Ä¢ Perfect correspondence between PDF content and analysis
‚Ä¢ Streamlined workflow for faster analysis

WHAT IT DOES:
‚Ä¢ Extracts images directly from PDF reports
‚Ä¢ Parses AI-generated tags from PDF content
‚Ä¢ Uses Kosmos-2 to explain WHY each tag was assigned
‚Ä¢ Generates detailed explainable AI reports
‚Ä¢ Saves results in both JSON and PDF formats

OUTPUT FILES:
‚Ä¢ direct_explainable_analysis_TIMESTAMP.json - Complete analysis data
‚Ä¢ explainable_ai_report_TIMESTAMP.pdf - Visual report with explanations

REQUIREMENTS:
‚Ä¢ PDF reports from the AI image tagging system
‚Ä¢ Sufficient memory for Kosmos-2 model (4GB+ recommended)
‚Ä¢ Internet connection for initial model download

ADVANTAGES OF DIRECT EXTRACTION:
‚Ä¢ No dataset path required
‚Ä¢ Perfect image-tag correspondence
‚Ä¢ Faster processing
‚Ä¢ No file matching issues
‚Ä¢ Simplified workflow
        """)
        print("="*70)

def main():
    """Main function for command-line usage"""
    parser = argparse.ArgumentParser(
        description="Explainable AI Analysis for Image Tagging Reports (Direct PDF Extraction)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python explainable_ai.py --analyze report.pdf
  python explainable_ai.py --scan /path/to/reports/
  python explainable_ai.py --interactive
        """
    )
    
    parser.add_argument("--analyze", type=str, 
                       help="Analyze a single PDF report")
    parser.add_argument("--scan", type=str, 
                       help="Scan directory for PDF reports and analyze all")
    parser.add_argument("--output", type=str, 
                       help="Output directory for results")
    parser.add_argument("--interactive", action="store_true", 
                       help="Run in interactive mode")
    
    args = parser.parse_args()
    
    # Initialize the interface
    interface = ExplainableAICommandInterface()
    
    try:
        if args.analyze:
            print("üî¨ Starting single PDF analysis...")
            result = interface.run_direct_analysis(args.analyze, args.output)
            interface._print_analysis_result(result)
            
        elif args.scan:
            print("üîç Starting batch PDF analysis...")
            results = interface.find_and_analyze_reports(args.scan)
            interface._print_batch_results(results)
            
        elif args.interactive:
            interface.interactive_mode()
            
        else:
            print("üî¨ Explainable AI Image Tagging Analyzer")
            print("üìÑ Direct PDF extraction - No dataset required!")
            print("Use --help for usage information or --interactive for interactive mode")
            interface.interactive_mode()
            
    except Exception as e:
        logger.error(f"‚ùå Fatal error: {e}")
        print(f"‚ùå Fatal error: {e}")
        sys.exit(1)

# Initialize the simplified command interface
command_interface = ExplainableAICommandInterface()
print("‚úÖ Simplified Command Interface (Direct PDF Extraction) initialized!")
print("\nüéâ All systems ready! You can now:")
print("   ‚Ä¢ Run main() for command-line interface")
print("   ‚Ä¢ Use command_interface.run_direct_analysis(pdf_path)")
print("   ‚Ä¢ Call command_interface.interactive_mode() for interactive use")
print("   ‚Ä¢ üìÑ NO dataset required - images extracted directly from PDF!")

if __name__ == "__main__":
    main()
    
"""
Cell 6: Enhanced Main Interface with Dataset Integration
Command-line interface for explainable AI analysis with compulsory dataset input
"""

class ExplainableAICommandInterface:
    """
    Enhanced command-line interface for the explainable AI system with dataset integration
    """
    
    def __init__(self):
        self.analyzer = explainable_analyzer
        self.report_generator = report_generator
        self.pdf_scanner = pdf_scanner
    
    def run_enhanced_analysis(self, pdf_path: str, dataset_path: str, output_dir: str = None) -> Dict[str, str]:
        """
        Run complete explainable AI analysis with dataset integration (COMPULSORY)
        """
        try:
            logger.info(f"üöÄ Starting enhanced explainable AI analysis with dataset integration...")
            logger.info(f"üìÑ PDF Path: {pdf_path}")
            logger.info(f"üìÅ Dataset Path: {dataset_path}")
            
            # Validate inputs
            if not os.path.exists(pdf_path):
                raise FileNotFoundError(f"PDF file not found: {pdf_path}")
            
            if not os.path.exists(dataset_path):
                raise FileNotFoundError(f"Dataset directory not found: {dataset_path}")
            
            # Set output directory
            if output_dir is None:
                output_dir = Path(pdf_path).parent
            else:
                output_dir = Path(output_dir)
                output_dir.mkdir(parents=True, exist_ok=True)
            
            # 1. Analyze PDF report with dataset integration
            logger.info("üìä Step 1: Analyzing PDF report with dataset integration using Kosmos-2...")
            analysis_results = self.analyzer.analyze_pdf_report_with_dataset(pdf_path, dataset_path)
            
            if not analysis_results:
                raise ValueError("No analysis results generated. Please check the PDF format, content, and dataset.")
            
            # 2. Get comparison summary
            comparison_summary = self.analyzer.get_comparison_summary()
            unmatched_images = self.analyzer.get_unmatched_images()
            
            # 3. Generate JSON results with dataset info
            logger.info("üíæ Step 2: Saving enhanced analysis results to JSON...")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            json_path = output_dir / f"enhanced_explainable_analysis_{timestamp}.json"
            saved_json = self.analyzer.save_results_to_json(str(json_path))
            
            # 4. Generate enhanced explainable AI report with images
            logger.info("üìã Step 3: Generating enhanced explainable AI PDF report with dataset comparison...")
            report_path = output_dir / f"enhanced_explainable_ai_report_{timestamp}.pdf"
            saved_report = self.report_generator.create_explainable_report(
                analysis_results, str(report_path)
            )
            
            # 5. Generate comparison report
            comparison_report_path = output_dir / f"dataset_comparison_summary_{timestamp}.txt"
            self._generate_comparison_summary_file(comparison_summary, unmatched_images, str(comparison_report_path))
            
            # 6. Generate summary
            stats = self.analyzer.generate_summary_statistics()
            
            results = {
                "status": "success",
                "pdf_analyzed": pdf_path,
                "dataset_used": dataset_path,
                "images_processed": len(analysis_results),
                "images_matched": comparison_summary.get('matched_images', 0),
                "match_percentage": comparison_summary.get('match_percentage', 0),
                "json_output": saved_json,
                "report_output": saved_report,
                "comparison_summary": str(comparison_report_path),
                "analysis_timestamp": timestamp,
                "statistics": stats
            }
            
            logger.info("üéâ Enhanced analysis complete!")
            logger.info(f"üìä Dataset Matching: {comparison_summary.get('matched_images', 0)}/{comparison_summary.get('total_pdf_images', 0)} images matched ({comparison_summary.get('match_percentage', 0)}%)")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Enhanced analysis failed: {e}")
            return {
                "status": "error",
                "error_message": str(e),
                "pdf_analyzed": pdf_path,
                "dataset_used": dataset_path if 'dataset_path' in locals() else 'Unknown'
            }
    
    def _generate_comparison_summary_file(self, comparison_summary: Dict, unmatched_images: List[str], output_path: str):
        """
        Generate a detailed comparison summary text file
        """
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("DATASET COMPARISON SUMMARY REPORT\n")
                f.write("=" * 50 + "\n\n")
                
                f.write(f"Analysis Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("OVERVIEW:\n")
                f.write(f"‚Ä¢ Total PDF Images: {comparison_summary.get('total_pdf_images', 0)}\n")
                f.write(f"‚Ä¢ Total Dataset Images: {comparison_summary.get('total_dataset_images', 0)}\n")
                f.write(f"‚Ä¢ Successfully Matched: {comparison_summary.get('matched_images', 0)}\n")
                f.write(f"‚Ä¢ Unmatched Images: {comparison_summary.get('unmatched_images', 0)}\n")
                f.write(f"‚Ä¢ Match Success Rate: {comparison_summary.get('match_percentage', 0)}%\n\n")
                
                if unmatched_images:
                    f.write("UNMATCHED IMAGES:\n")
                    f.write("-" * 20 + "\n")
                    for i, img_name in enumerate(unmatched_images, 1):
                        f.write(f"{i}. {img_name}\n")
                    f.write(f"\nTotal Unmatched: {len(unmatched_images)}\n\n")
                else:
                    f.write("‚úÖ ALL IMAGES SUCCESSFULLY MATCHED!\n\n")
                
                f.write("RECOMMENDATIONS:\n")
                f.write("-" * 15 + "\n")
                match_rate = comparison_summary.get('match_percentage', 0)
                
                if match_rate == 100:
                    f.write("‚Ä¢ Perfect match rate achieved!\n")
                    f.write("‚Ä¢ Dataset is complete and well-organized\n")
                elif match_rate >= 90:
                    f.write("‚Ä¢ Excellent match rate\n")
                    f.write("‚Ä¢ Minor gaps in dataset or naming inconsistencies\n")
                elif match_rate >= 70:
                    f.write("‚Ä¢ Good match rate with room for improvement\n")
                    f.write("‚Ä¢ Check for missing images in dataset\n")
                    f.write("‚Ä¢ Verify filename consistency\n")
                elif match_rate >= 50:
                    f.write("‚Ä¢ Moderate match rate - action needed\n")
                    f.write("‚Ä¢ Significant dataset gaps detected\n")
                    f.write("‚Ä¢ Review dataset completeness and organization\n")
                else:
                    f.write("‚Ä¢ Low match rate - immediate attention required\n")
                    f.write("‚Ä¢ Dataset may be incomplete or incorrectly structured\n")
                    f.write("‚Ä¢ Check file paths and naming conventions\n")
                
            logger.info(f"üìã Comparison summary saved to: {output_path}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to generate comparison summary: {e}")
    
    def find_and_analyze_reports_with_dataset(self, directory: str, dataset_path: str) -> List[Dict[str, str]]:
        """
        Find all PDF reports in a directory and analyze them with dataset integration
        """
        try:
            logger.info(f"üîç Searching for PDF reports in: {directory}")
            logger.info(f"üìÅ Using dataset: {dataset_path}")
            
            pdf_files = self.pdf_scanner.find_pdf_reports(directory)
            
            if not pdf_files:
                logger.warning("‚ö†Ô∏è No PDF files found in directory")
                return []
            
            logger.info(f"üìÅ Found {len(pdf_files)} PDF files")
            
            results = []
            for i, pdf_path in enumerate(pdf_files, 1):
                logger.info(f"üìä Processing PDF {i}/{len(pdf_files)}: {Path(pdf_path).name}")
                
                result = self.run_enhanced_analysis(pdf_path, dataset_path, directory)
                result["pdf_index"] = i
                result["total_pdfs"] = len(pdf_files)
                results.append(result)
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Failed to find and analyze reports with dataset: {e}")
            return []
    
    def interactive_mode(self):
        """
        Enhanced interactive command-line mode with separate dataset input
        """
        print("\n" + "="*80)
        print("üî¨ ENHANCED EXPLAINABLE AI IMAGE TAGGING ANALYZER")
        print("   Powered by Kosmos-2 Vision-Language Model with Dataset Integration")
        print("   üìÅ Dataset input is COMPULSORY for all analysis")
        print("="*80)
        
        while True:
            try:
                print("\nüìã Available Commands:")
                print("  1. analyze                               - Analyze single PDF with dataset")
                print("  2. scan                                  - Analyze all PDFs in directory with dataset")
                print("  3. validate                              - Validate dataset structure")
                print("  4. status                                - Show system status")
                print("  5. help                                  - Show detailed help")
                print("  6. quit                                  - Exit program")
                
                command = input("\nüî¨ enhanced-ai> ").strip().lower()
                
                if not command:
                    continue
                
                if command in ['quit', 'exit', 'q']:
                    print("üëã Goodbye!")
                    break
                
                elif command == 'analyze':
                    # Get PDF path
                    pdf_path = input("üìÑ Enter PDF report path: ").strip().strip('"\'')
                    if not pdf_path:
                        print("‚ùå PDF path cannot be empty!")
                        continue
                    
                    # Get dataset path separately
                    dataset_path = input("üìÅ Enter dataset directory path: ").strip().strip('"\'')
                    if not dataset_path:
                        print("‚ùå Dataset path cannot be empty!")
                        continue
                    
                    print(f"\nüî¨ Analyzing PDF: {pdf_path}")
                    print(f"üìÅ Using Dataset: {dataset_path}")
                    
                    result = self.run_enhanced_analysis(pdf_path, dataset_path)
                    self._print_enhanced_analysis_result(result)
                
                elif command == 'scan':
                    # Get directory path
                    directory = input("üìÇ Enter directory containing PDF reports: ").strip().strip('"\'')
                    if not directory:
                        print("‚ùå Directory path cannot be empty!")
                        continue
                    
                    # Get dataset path separately
                    dataset_path = input("üìÅ Enter dataset directory path: ").strip().strip('"\'')
                    if not dataset_path:
                        print("‚ùå Dataset path cannot be empty!")
                        continue
                    
                    print(f"\nüîç Scanning directory: {directory}")
                    print(f"üìÅ Using Dataset: {dataset_path}")
                    
                    results = self.find_and_analyze_reports_with_dataset(directory, dataset_path)
                    self._print_enhanced_batch_results(results)
                
                elif command == 'validate':
                    # Get dataset path for validation
                    dataset_path = input("üìÅ Enter dataset directory path to validate: ").strip().strip('"\'')
                    if not dataset_path:
                        print("‚ùå Dataset path cannot be empty!")
                        continue
                    
                    self._validate_dataset(dataset_path)
                
                elif command == 'status':
                    self._print_enhanced_system_status()
                
                elif command == 'help':
                    self._print_enhanced_detailed_help()
                
                else:
                    print("‚ùå Invalid command.")
                    print("üí° Available commands: analyze, scan, validate, status, help, quit")
                    
            except KeyboardInterrupt:
                print("\n\nüëã Interrupted by user. Goodbye!")
                break
            except Exception as e:
                print(f"‚ùå Error: {e}")
                logger.error(f"Interactive mode error: {e}")
    
    def _validate_dataset(self, dataset_path: str):
        """
        Enhanced dataset validation with detailed feedback
        """
        try:
            print(f"\nüîç Validating dataset: {dataset_path}")
            
            # Check if path exists
            if not os.path.exists(dataset_path):
                print(f"‚ùå Dataset directory not found: {dataset_path}")
                print("üí° Please check the path and try again")
                return
            
            # Check if it's a directory
            if not os.path.isdir(dataset_path):
                print(f"‚ùå Path is not a directory: {dataset_path}")
                return
            
            print("üìÅ Directory found, scanning for images...")
            
            # Load dataset using analyzer
            success = self.analyzer.load_dataset(dataset_path)
            
            if success:
                dataset_info = self.analyzer.dataset_images
                print(f"‚úÖ Dataset validation successful!")
                print(f"üìä Found {len(dataset_info)} images in dataset")
                
                if len(dataset_info) == 0:
                    print("‚ö†Ô∏è No supported image files found in dataset")
                    print("üí° Supported formats: JPG, JPEG, PNG, BMP, TIFF, TIF, WebP")
                    return
                
                # Show format breakdown
                formats = {}
                total_size = 0
                for img_info in dataset_info.values():
                    ext = img_info['extension']
                    formats[ext] = formats.get(ext, 0) + 1
                    total_size += img_info.get('size', 0)
                
                print(f"üìÇ File formats: {dict(formats)}")
                print(f"üíæ Total dataset size: {total_size / (1024*1024):.1f} MB")
                
                # Show sample filenames
                sample_files = list(dataset_info.keys())[:5]
                print(f"üìÑ Sample files: {sample_files}")
                
                if len(dataset_info) > 5:
                    print(f"   ... and {len(dataset_info) - 5} more files")
                
                print(f"‚úÖ Dataset is ready for analysis!")
                
            else:
                print(f"‚ùå Dataset validation failed!")
                print("üí° Check if the directory contains supported image files")
                
        except Exception as e:
            print(f"‚ùå Dataset validation error: {e}")
            logger.error(f"Dataset validation error: {e}")
    
    def _print_enhanced_analysis_result(self, result: Dict[str, str]):
        """Print enhanced analysis result with detailed dataset information"""
        print("\n" + "="*70)
        
        if result["status"] == "success":
            print("‚úÖ ENHANCED ANALYSIS SUCCESSFUL")
            print(f"üìÑ PDF Analyzed: {result['pdf_analyzed']}")
            print(f"üìÅ Dataset Used: {result['dataset_used']}")
            print(f"üñºÔ∏è  Images Processed: {result['images_processed']}")
            print(f"üîó Images Matched: {result['images_matched']}/{result['images_processed']} ({result['match_percentage']}%)")
            
            # Enhanced matching feedback
            match_rate = result['match_percentage']
            if match_rate == 100:
                print("üéâ Perfect dataset matching achieved!")
            elif match_rate >= 90:
                print("‚úÖ Excellent dataset matching rate")
            elif match_rate >= 70:
                print("‚ö†Ô∏è Good matching rate - minor gaps detected")
            elif match_rate >= 50:
                print("‚ö†Ô∏è Moderate matching rate - check dataset completeness")
            else:
                print("‚ùå Low matching rate - dataset may be incomplete")
            
            print(f"\nüìã Generated Files:")
            print(f"   üíæ JSON Results: {result['json_output']}")
            print(f"   üìä Enhanced Report: {result['report_output']}")
            print(f"   üìà Comparison Summary: {result['comparison_summary']}")
            
            if "statistics" in result:
                stats = result["statistics"]
                print(f"\nüìä Enhanced Statistics:")
                print(f"   ‚Ä¢ Total Tags Explained: {stats.get('total_tags_explained', 'N/A')}")
                print(f"   ‚Ä¢ Average Tags per Image: {stats.get('average_tags_per_image', 'N/A')}")
                
                if stats.get('most_common_tags'):
                    most_common = list(stats['most_common_tags'].items())[:3]
                    tags_str = ', '.join([f'{tag}({count})' for tag, count in most_common])
                    print(f"   ‚Ä¢ Most Common Tags: {tags_str}")
            
            print(f"\nüéØ Next Steps:")
            print(f"   1. Check the enhanced PDF report for visual comparisons")
            print(f"   2. Review the comparison summary for dataset validation")
            print(f"   3. Examine unmatched images if match rate < 100%")
            
        else:
            print("‚ùå ENHANCED ANALYSIS FAILED")
            print(f"üìÑ PDF: {result['pdf_analyzed']}")
            print(f"üìÅ Dataset: {result['dataset_used']}")
            print(f"‚ùå Error: {result['error_message']}")
            
            # Provide troubleshooting tips
            print(f"\nüõ†Ô∏è Troubleshooting Tips:")
            if "not found" in result['error_message'].lower():
                print(f"   ‚Ä¢ Check if the file/directory paths exist")
                print(f"   ‚Ä¢ Use absolute paths instead of relative paths")
                print(f"   ‚Ä¢ Ensure proper file permissions")
            elif "pdf" in result['error_message'].lower():
                print(f"   ‚Ä¢ Verify the PDF is a valid image analysis report")
                print(f"   ‚Ä¢ Check if PDF contains embedded images")
            elif "dataset" in result['error_message'].lower():
                print(f"   ‚Ä¢ Ensure dataset directory contains image files")
                print(f"   ‚Ä¢ Check supported formats: JPG, PNG, BMP, TIFF, WebP")
            
        print("="*70)
    
    def _print_enhanced_batch_results(self, results: List[Dict[str, str]]):
        """Print enhanced batch analysis results with dataset information"""
        print("\n" + "="*70)
        print("üìä ENHANCED BATCH ANALYSIS RESULTS")
        print("="*70)
        
        successful = [r for r in results if r["status"] == "success"]
        failed = [r for r in results if r["status"] == "error"]
        
        print(f"‚úÖ Successful: {len(successful)}")
        print(f"‚ùå Failed: {len(failed)}")
        
        if successful:
            total_images = sum(r["images_processed"] for r in successful)
            total_matched = sum(r["images_matched"] for r in successful)
            overall_match_rate = (total_matched / total_images) * 100 if total_images > 0 else 0
            
            print(f"üñºÔ∏è  Total Images Processed: {total_images}")
            print(f"üîó Total Images Matched: {total_matched} ({overall_match_rate:.1f}%)")
            
            print("\nüìã Generated Reports:")
            for result in successful:
                pdf_name = Path(result["pdf_analyzed"]).name
                match_info = f"{result['images_matched']}/{result['images_processed']} matched"
                print(f"   ‚Ä¢ {pdf_name} ‚Üí {result['images_processed']} images ({match_info})")
        
        if failed:
            print("\n‚ùå Failed Analyses:")
            for result in failed:
                pdf_name = Path(result["pdf_analyzed"]).name
                print(f"   ‚Ä¢ {pdf_name}: {result['error_message']}")
        
        print("="*70)
    
    def _print_enhanced_system_status(self):
        """Print enhanced system status information"""
        print("\n" + "="*60)
        print("üîß ENHANCED SYSTEM STATUS")
        print("="*60)
        print(f"ü§ñ Kosmos-2 Model: Loaded")
        print(f"üíª Device: {kosmos_explainer.device}")
        print(f"üìÑ PDF Scanner: Ready")
        print(f"üìã Enhanced Report Generator: Ready")
        print(f"üìÅ Dataset Integration: Enabled (COMPULSORY)")
        print(f"üîó Image Comparison: Enabled")
        print(f"üïí Current Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Check if dataset is loaded
        if hasattr(explainable_analyzer, 'dataset_path') and explainable_analyzer.dataset_path:
            print(f"üìÇ Current Dataset: {explainable_analyzer.dataset_path}")
            print(f"üìä Dataset Images: {len(explainable_analyzer.dataset_images)}")
        else:
            print(f"üìÇ Current Dataset: None loaded")
        
        print("="*60)
    
    def _print_enhanced_detailed_help(self):
        """Print enhanced detailed help information"""
        print("\n" + "="*80)
        print("üìö ENHANCED DETAILED HELP")
        print("="*80)
        print("""
üî¨ ENHANCED EXPLAINABLE AI IMAGE TAGGING ANALYZER

This system analyzes PDF reports generated by the AI image tagging system
and provides explainable AI insights using Kosmos-2 with COMPULSORY dataset integration.

COMMANDS:
  analyze <pdf_path> <dataset_path>  - Analyze a single PDF report with dataset
                                      Example: analyze "report.pdf" "/path/to/images/"
  
  scan <directory> <dataset_path>    - Find and analyze all PDF reports with dataset
                                      Example: scan "/reports/" "/path/to/images/"
  
  validate <dataset_path>           - Validate dataset structure and contents
                                      Example: validate "/path/to/images/"
  
  status                           - Show current system status and configuration
  
  help                            - Show this detailed help information
  
  quit                            - Exit the program

ENHANCED FEATURES:
‚Ä¢ COMPULSORY dataset integration for validation
‚Ä¢ Side-by-side comparison of PDF vs original images
‚Ä¢ Image quality and similarity analysis
‚Ä¢ Dataset matching statistics and reporting
‚Ä¢ Enhanced PDF reports with both image versions
‚Ä¢ Detailed comparison summary files

WHAT IT DOES:
‚Ä¢ Scans PDF reports generated by the image tagging system
‚Ä¢ REQUIRES original dataset path for image validation
‚Ä¢ Matches PDF images with original dataset images
‚Ä¢ Uses Kosmos-2 to explain WHY each tag was assigned
‚Ä¢ Compares image quality between PDF and original versions
‚Ä¢ Generates enhanced explainable AI reports with both images
‚Ä¢ Creates dataset validation and comparison summaries

OUTPUT FILES:
‚Ä¢ enhanced_explainable_analysis_TIMESTAMP.json - Complete analysis data
‚Ä¢ enhanced_explainable_ai_report_TIMESTAMP.pdf - Visual report with comparisons
‚Ä¢ dataset_comparison_summary_TIMESTAMP.txt - Matching validation summary

REQUIREMENTS:
‚Ä¢ PDF reports from the AI image tagging system
‚Ä¢ Original dataset directory (COMPULSORY)
‚Ä¢ Sufficient memory for Kosmos-2 model (4GB+ recommended)
‚Ä¢ Internet connection for initial model download

DATASET REQUIREMENTS:
‚Ä¢ Must contain original images used to generate the PDF report
‚Ä¢ Supported formats: JPG, PNG, BMP, TIFF, WebP
‚Ä¢ Filenames should match or be similar to those in PDF report
‚Ä¢ Recommended: Organized directory structure
        """)
        print("="*80)

def main():
    """Enhanced main function for command-line usage with dataset requirement"""
    parser = argparse.ArgumentParser(
        description="Enhanced Explainable AI Analysis for Image Tagging Reports with Dataset Integration",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python explainable_ai.py --analyze report.pdf --dataset /path/to/images/
  python explainable_ai.py --scan /path/to/reports/ --dataset /path/to/images/
  python explainable_ai.py --interactive
        """
    )
    
    parser.add_argument("--analyze", type=str, 
                       help="Analyze a single PDF report")
    parser.add_argument("--scan", type=str, 
                       help="Scan directory for PDF reports and analyze all")
    parser.add_argument("--dataset", type=str, required=False,
                       help="Dataset directory path (COMPULSORY for analysis)")
    parser.add_argument("--output", type=str, 
                       help="Output directory for results")
    parser.add_argument("--interactive", action="store_true", 
                       help="Run in interactive mode")
    
    args = parser.parse_args()
    
    # Initialize the enhanced interface
    interface = ExplainableAICommandInterface()
    
    try:
        if args.analyze:
            if not args.dataset:
                print("‚ùå Error: --dataset parameter is COMPULSORY for analysis!")
                print("üí° Example: python explainable_ai.py --analyze report.pdf --dataset /path/to/images/")
                sys.exit(1)
            
            print("üî¨ Starting enhanced single PDF analysis...")
            result = interface.run_enhanced_analysis(args.analyze, args.dataset, args.output)
            interface._print_enhanced_analysis_result(result)
            
        elif args.scan:
            if not args.dataset:
                print("‚ùå Error: --dataset parameter is COMPULSORY for batch analysis!")
                print("üí° Example: python explainable_ai.py --scan /reports/ --dataset /path/to/images/")
                sys.exit(1)
            
            print("üîç Starting enhanced batch PDF analysis...")
            results = interface.find_and_analyze_reports_with_dataset(args.scan, args.dataset)
            interface._print_enhanced_batch_results(results)
            
        elif args.interactive:
            interface.interactive_mode()
            
        else:
            print("üî¨ Enhanced Explainable AI Image Tagging Analyzer")
            print("üìÅ Dataset integration is COMPULSORY for all analysis")
            print("Use --help for usage information or --interactive for interactive mode")
            interface.interactive_mode()
            
    except Exception as e:
        logger.error(f"‚ùå Fatal error: {e}")
        print(f"‚ùå Fatal error: {e}")
        sys.exit(1)

# Initialize the enhanced command interface
command_interface = ExplainableAICommandInterface()
print("‚úÖ Enhanced Command Interface with Dataset Integration initialized!")
print("\nüéâ All enhanced systems ready! You can now:")
print("   ‚Ä¢ Run main() for enhanced command-line interface")
print("   ‚Ä¢ Use command_interface.run_enhanced_analysis(pdf_path, dataset_path)")
print("   ‚Ä¢ Call command_interface.interactive_mode() for enhanced interactive use")
print("   ‚Ä¢ üìÅ REMEMBER: Dataset path is COMPULSORY for all analysis!")

if __name__ == "__main__":
    main()

"""
Cell 7: Usage Examples and Testing
Examples of how to use the explainable AI system
"""

def demo_usage_examples():
    """
    Demonstrate different ways to use the explainable AI system
    """
    print("üéØ USAGE EXAMPLES FOR EXPLAINABLE AI SYSTEM")
    print("="*60)
    
    print("\n1Ô∏è‚É£  SINGLE PDF ANALYSIS:")
    print("   # Analyze a specific PDF report")
    print("   result = command_interface.run_analysis('/path/to/report.pdf')")
    print("   print(f'Processed {result[\"images_processed\"]} images')")
    
    print("\n2Ô∏è‚É£  BATCH DIRECTORY ANALYSIS:")
    print("   # Analyze all PDF reports in a directory")
    print("   results = command_interface.find_and_analyze_reports('/path/to/reports/')")
    print("   successful = [r for r in results if r['status'] == 'success']")
    print("   print(f'Successfully analyzed {len(successful)} PDFs')")
    
    print("\n3Ô∏è‚É£  INTERACTIVE MODE:")
    print("   # Start interactive command-line interface")
    print("   command_interface.interactive_mode()")
    
    print("\n4Ô∏è‚É£  COMMAND LINE USAGE:")
    print("   # From terminal:")
    print("   python explainable_ai.py --analyze report.pdf")
    print("   python explainable_ai.py --scan /reports/")
    print("   python explainable_ai.py --interactive")
    
    print("\n5Ô∏è‚É£  PROGRAMMATIC ACCESS:")
    print("   # Direct access to components")
    print("   pdf_data = pdf_scanner.scan_pdf_report('report.pdf')")
    print("   explanations = kosmos_explainer.generate_explanation(image, tags)")
    print("   report_path = report_generator.create_explainable_report(results)")

def test_system_components():
    """
    Test individual system components
    """
    print("\nüß™ TESTING SYSTEM COMPONENTS")
    print("="*50)
    
    # Test 1: Check if Kosmos-2 is loaded
    print("‚úÖ Testing Kosmos-2 model loading...")
    try:
        device_info = kosmos_explainer.device
        model_name = kosmos_explainer.model_name
        print(f"   Model: {model_name}")
        print(f"   Device: {device_info}")
        print("   ‚úÖ Kosmos-2 loaded successfully")
    except Exception as e:
        print(f"   ‚ùå Kosmos-2 loading failed: {e}")
    
    # Test 2: PDF Scanner
    print("\n‚úÖ Testing PDF scanner...")
    try:
        # This is a theoretical test - would need actual PDF file
        print("   PDF scanner initialized and ready")
        print("   ‚úÖ PDF scanner working")
    except Exception as e:
        print(f"   ‚ùå PDF scanner error: {e}")
    
    # Test 3: Report Generator
    print("\n‚úÖ Testing report generator...")
    try:
        # Test report generator initialization
        styles = report_generator.styles
        print("   Report styles loaded")
        print("   ‚úÖ Report generator working")
    except Exception as e:
        print(f"   ‚ùå Report generator error: {e}")
    
    print("\nüéØ SYSTEM STATUS: All components initialized!")

def create_sample_workflow():
    """
    Create a sample workflow for processing PDF reports
    """
    print("\nüìã SAMPLE WORKFLOW")
    print("="*50)
    
    workflow_code = '''
# STEP-BY-STEP WORKFLOW FOR EXPLAINABLE AI ANALYSIS

# 1. Set up paths
pdf_path = "/path/to/your/image_analysis_report.pdf"
output_directory = "/path/to/output/"

# 2. Run complete analysis
print("üî¨ Starting explainable AI analysis...")
result = command_interface.run_analysis(pdf_path, output_directory)

# 3. Check results
if result["status"] == "success":
    print(f"‚úÖ Success! Processed {result['images_processed']} images")
    print(f"üìÑ Report saved to: {result['report_output']}")
    print(f"üíæ Data saved to: {result['json_output']}")
    
    # 4. Access specific explanations
    analyzer = explainable_analyzer
    
    # Get explanation for a specific tag on a specific image
    explanation = analyzer.get_tag_explanation(image_index=1, tag="tree")
    print(f"üè∑Ô∏è  Why 'tree' tag: {explanation}")
    
    # 5. Get summary statistics
    stats = analyzer.generate_summary_statistics()
    print(f"üìä Total tags explained: {stats['total_tags_explained']}")
    print(f"üìä Average tags per image: {stats['average_tags_per_image']}")
    
else:
    print(f"‚ùå Analysis failed: {result['error_message']}")

# 6. For batch processing
batch_results = command_interface.find_and_analyze_reports("/reports/")
successful_analyses = [r for r in batch_results if r["status"] == "success"]
print(f"üìä Batch complete: {len(successful_analyses)} successful analyses")
    '''
    
    print(workflow_code)

def show_expected_inputs_outputs():
    """
    Show what inputs the system expects and what outputs it generates
    """
    print("\nüì• EXPECTED INPUTS & üì§ OUTPUTS")
    print("="*60)
    
    print("\nüì• INPUT REQUIREMENTS:")
    print("   ‚Ä¢ PDF reports generated by the AI image tagging system")
    print("   ‚Ä¢ PDF should contain:")
    print("     - Images embedded in the PDF")
    print("     - AI-generated tags listed for each image")
    print("     - BLIP captions (optional)")
    print("     - LLaVA descriptions (optional)")
    print("   ‚Ä¢ Supported PDF naming patterns:")
    print("     - *image_analysis_report*.pdf")
    print("     - *ai_image_analysis_report*.pdf")
    print("     - *single_image_report*.pdf")
    
    print("\nüì§ OUTPUT FILES:")
    print("   1. Explainable AI Report (PDF):")
    print("      ‚Ä¢ File: explainable_ai_report_YYYYMMDD_HHMMSS.pdf")
    print("      ‚Ä¢ Contains: Visual explanations for each tag")
    print("      ‚Ä¢ Includes: Kosmos-2 reasoning and confidence assessments")
    
    print("\n   2. Analysis Results (JSON):")
    print("      ‚Ä¢ File: explainable_analysis_results_YYYYMMDD_HHMMSS.json")
    print("      ‚Ä¢ Contains: Raw analysis data in structured format")
    print("      ‚Ä¢ Includes: All explanations, statistics, and metadata")
    
    print("\nüìä EXAMPLE OUTPUT STRUCTURE:")
    example_output = '''
    {
      "analysis_metadata": {
        "total_images": 5,
        "analysis_timestamp": "2025-07-26T14:30:22",
        "model_used": "microsoft/kosmos-2-patch14-224"
      },
      "summary_statistics": {
        "total_tags_explained": 47,
        "average_tags_per_image": 9.4,
        "most_common_tags": {"tree": 3, "building": 2, "person": 2}
      },
      "image_analyses": [
        {
          "image_index": 1,
          "file_name": "landscape.jpg",
          "original_tags": ["tree", "sky", "building"],
          "kosmos_explanations": {
            "general_description": "The image shows a landscape with...",
            "tag_explanations": {
              "tree": "Multiple trees are visible in the foreground...",
              "sky": "A clear blue sky occupies the upper portion...",
              "building": "A structure is visible in the background..."
            },
            "confidence_assessment": "High confidence in main elements..."
          }
        }
      ]
    }
    '''
    print(example_output)

def demonstrate_key_features():
    """
    Demonstrate the key features of the explainable AI system
    """
    print("\nüéØ KEY FEATURES DEMONSTRATION")
    print("="*60)
    
    print("\nüîç FEATURE 1: TAG EXPLANATION")
    print("   For each AI-generated tag, Kosmos-2 explains:")
    print("   ‚Ä¢ WHERE in the image the tag is relevant")
    print("   ‚Ä¢ WHY the tag was assigned")
    print("   ‚Ä¢ WHAT visual evidence supports the tag")
    print("   Example: 'tree' ‚Üí 'Multiple green leafy structures visible in the foreground'")
    
    print("\nüß† FEATURE 2: VISUAL REASONING")
    print("   Kosmos-2 provides:")
    print("   ‚Ä¢ Detailed visual understanding of the scene")
    print("   ‚Ä¢ Contextual relationships between objects")
    print("   ‚Ä¢ Spatial reasoning and layout description")
    
    print("\nüìä FEATURE 3: CONFIDENCE ASSESSMENT")
    print("   System evaluates:")
    print("   ‚Ä¢ Clarity of visual elements")
    print("   ‚Ä¢ Certainty of object identification")
    print("   ‚Ä¢ Overall image quality assessment")
    
    print("\nüìã FEATURE 4: COMPREHENSIVE REPORTING")
    print("   Generated reports include:")
    print("   ‚Ä¢ Side-by-side image and explanation comparison")
    print("   ‚Ä¢ Original AI model outputs (BLIP, LLaVA)")
    print("   ‚Ä¢ Statistical analysis of tag patterns")
    print("   ‚Ä¢ Key insights and conclusions")
    
    print("\nüîÑ FEATURE 5: BATCH PROCESSING")
    print("   System can:")
    print("   ‚Ä¢ Process multiple PDF reports automatically")
    print("   ‚Ä¢ Generate summary statistics across all images")
    print("   ‚Ä¢ Create consolidated reports for large datasets")

def show_troubleshooting_guide():
    """
    Show common issues and solutions
    """
    print("\nüõ†Ô∏è TROUBLESHOOTING GUIDE")
    print("="*50)
    
    print("\n‚ùå COMMON ISSUES & SOLUTIONS:")
    
    print("\n1. 'No images found in PDF'")
    print("   ‚úÖ Solutions:")
    print("   ‚Ä¢ Ensure PDF contains embedded images")
    print("   ‚Ä¢ Check if PDF was generated by the AI tagging system")
    print("   ‚Ä¢ Verify PDF is not corrupted")
    
    print("\n2. 'Kosmos-2 model loading failed'")
    print("   ‚úÖ Solutions:")
    print("   ‚Ä¢ Check internet connection for model download")
    print("   ‚Ä¢ Ensure sufficient RAM (4GB+ recommended)")
    print("   ‚Ä¢ Try CPU mode if GPU memory insufficient")
    
    print("\n3. 'Analysis takes too long'")
    print("   ‚úÖ Solutions:")
    print("   ‚Ä¢ Use GPU acceleration if available")
    print("   ‚Ä¢ Process fewer images per batch")
    print("   ‚Ä¢ Reduce max_tags parameter")
    
    print("\n4. 'Poor explanation quality'")
    print("   ‚úÖ Solutions:")
    print("   ‚Ä¢ Ensure input images have good quality")
    print("   ‚Ä¢ Check if original tags are meaningful")
    print("   ‚Ä¢ Try adjusting Kosmos-2 temperature parameters")
    
    print("\n5. 'PDF report generation fails'")
    print("   ‚úÖ Solutions:")
    print("   ‚Ä¢ Check disk space availability")
    print("   ‚Ä¢ Ensure write permissions in output directory")
    print("   ‚Ä¢ Verify ReportLab installation")

def run_all_examples():
    """
    Run all demonstration functions
    """
    demo_usage_examples()
    test_system_components()
    create_sample_workflow()
    show_expected_inputs_outputs()
    demonstrate_key_features()
    show_troubleshooting_guide()
    
    print("\n" + "="*70)
    print("üéâ SYSTEM READY FOR USE!")
    print("="*70)
    print("\nüöÄ To get started:")
    print("   1. Prepare a PDF report from the AI image tagging system")
    print("   2. Run: command_interface.run_analysis('path/to/report.pdf')")
    print("   3. Or use interactive mode: command_interface.interactive_mode()")
    print("\nüìö For help: Use --help flag or call show_troubleshooting_guide()")

# Quick start function
def quick_start_guide():
    """
    Quick start guide for immediate usage
    """
    print("\n‚ö° QUICK START GUIDE")
    print("="*40)
    print("\n1Ô∏è‚É£  Have a PDF report ready from the AI image tagging system")
    print("2Ô∏è‚É£  Run ONE of these commands:")
    print()
    print("   # For single PDF analysis:")
    print("   result = command_interface.run_analysis('/path/to/your/report.pdf')")
    print()
    print("   # For interactive mode:")
    print("   command_interface.interactive_mode()")
    print()
    print("   # For batch processing:")
    print("   results = command_interface.find_and_analyze_reports('/path/to/reports/')")
    print()
    print("3Ô∏è‚É£  Check the output files generated in the same directory")
    print("4Ô∏è‚É£  Review the explainable AI report PDF for insights!")
    print("\n‚ú® That's it! Your explainable AI analysis is complete.")

# Execute examples (comment out if not needed)
print("\n" + "üéØ" * 20)
print("EXPLAINABLE AI SYSTEM - READY TO USE!")
print("üéØ" * 20)

# Uncomment the line below to see all examples
# run_all_examples()

# Show quick start by default
quick_start_guide()

print("\nüí° TIP: Call run_all_examples() to see detailed usage information")
print("üí° TIP: Call main() to start the command-line interface")
